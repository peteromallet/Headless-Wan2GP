# File Output Standardization - Master Document

**Date:** 2025-12-17
**Status:** Phase 1 Complete âœ… | Phase 1.5 Ready | Phase 2-4 Planned
**Author:** Analysis based on codebase investigation

---

## ğŸ“š Document Purpose

This is the **MASTER DOCUMENT** for file output standardization. It contains:
- Complete analysis of current system
- Implementation plan for all phases
- Phase 1 implementation details and validation
- Phase 2-4 specifications with testing loops

**Quick Links:**
- [Phase 1 Status](#phase-1-status) - What's been done
- [Phase 1.5 Validation](#phase-15-production-validation-required---zero-risk) - What to do tomorrow
- [Phase 2 Plan](#phase-2-standardize-task-output-paths-medium-risk) - What's next

---

## ğŸ“Š Phase 1 Status

### âœ… Implementation Complete + Fully Tested

**Commits:**
- `ee6f057` - Initial implementation (parameters added)
- `285691f` - Critical fix #1 (image_save_path) + validation phase
- `5cfb855` - Quick validation checklist
- `57a2af5` - **Critical fix #2 (wgp.apply_changes timing issue) - REQUIRED FOR PRODUCTION!**
- `6d3ce6a` - Real generation test (end-to-end validation)

**Files Changed:**
- `headless_wgp.py` - Added `main_output_dir` parameter + critical timing fixes
- `headless_model_management.py` - Added `main_output_dir` parameter
- `worker.py` - Pass configured `--main-output-dir` to task queue
- `test_phase1_output_dir.py` - Full integration test (validates with real WGP)
- `test_phase1_static.py` - Fast static validation test

**What Works Now:**
- âœ… WGP respects worker's `--main-output-dir` configuration
- âœ… Both video tasks (save_path) and image tasks (image_save_path) consolidated
- âœ… Paths survive wgp.apply_changes() calls (critical timing fix)
- âœ… Backwards compatible (defaults to old behavior if not configured)
- âœ… **All validation tests passed** (tested with real WGP environment)

**Critical Fixes Applied:**
1. **image_save_path Missing (commit `285691f`)**
   - WGP uses two separate config keys: `save_path` (videos) and `image_save_path` (images)
   - Initial implementation only set `save_path`, so images would still go to old location
   - **Fix:** Added `image_save_path` to server_config

2. **wgp.apply_changes() Timing Issue (commit `57a2af5`) - CRITICAL!**
   - WGP has module-level variables AND a server_config dictionary
   - `wgp.apply_changes()` reads from dict â†’ module vars, overwriting our changes
   - **Fix:** Set paths in TWO places: after wgp import AND after apply_changes()
   - **Without this fix, all files would still go to old location in production!**

**Risk Assessment:**
- Risk Level: Very Low âœ…
- Confidence: **99.5%** (full end-to-end validation with real generation)
- Rollback: Easy (optional parameters, no breaking changes)
- **Validation Level:** Complete (config + integration + real generation)

**What's NOT Active Yet:**
- Code is deployed but requires worker restart to activate
- Files still going to old locations until restart
- Phase 1.5 validation will activate and verify in production

### ğŸ” Testing Performed

**Static Validation (test_phase1_static.py):**
- âœ… Parameter flow: worker.py â†’ HeadlessTaskQueue â†’ WanOrchestrator
- âœ… Both save_path and image_save_path configured
- âœ… Backwards compatibility (optional parameters with None defaults)

**Integration Testing (test_phase1_output_dir.py):**
- âœ… Full WGP initialization with configured output directory
- âœ… Verified all 4 configuration points:
  - `wgp.save_path` (module-level variable for videos)
  - `wgp.image_save_path` (module-level variable for images)
  - `wgp.server_config['save_path']` (dictionary)
  - `wgp.server_config['image_save_path']` (dictionary)
- âœ… Paths persist through wgp.apply_changes() calls
- âœ… Test environment: RTX 4090, CUDA 12.4, PyTorch with full WGP dependencies

**Real Generation Testing (test_phase1_real_generation.py):**
- âœ… End-to-end test with actual image generation
- âœ… Model: Flux 1 Dev 12B (loaded successfully)
- âœ… Generated test image: "a red apple on a table" (512x512, 4 steps)
- âœ… Generation time: 208.8 seconds
- âœ… Output file: `/test_phase1_real_outputs/2025-12-17-15h36m21s_seed42_a red apple on a table_3.png`
- âœ… File saved to configured directory (NOT old Wan2GP/outputs/ location)
- âœ… PNG conversion worked correctly
- âœ… **This is the ultimate validation: actual files being saved to the right place!**

### ğŸ” Gotchas Found During Testing

**1. image_save_path Missing (FIXED)**
- **Status:** âœ… FIXED in commit `285691f`

**2. wgp.apply_changes() Resets Paths (FIXED) - CRITICAL!**
- **Problem:** WGP's module-level code structure:
  - Line 2347-2348: `save_path = server_config.get("save_path", "outputs/")`
  - Line 3068: `wgp.apply_changes()` reads dict â†’ module vars
  - Our paths were set BEFORE apply_changes(), so they got reset!
- **Discovery:** Found through integration testing with real WGP environment
- **Impact:** Without this fix, ALL files would still go to `Wan2GP/outputs/` despite config
- **Fix Applied:** Set paths in two places (after import AND after apply_changes)
- **Status:** âœ… FIXED in commit `57a2af5`
- **Validation:** Integration test now passes with all 4 config points correct

**Other Checks (All Safe):**
- âœ… Multiple instantiation points (backwards compatible)
- âœ… File upload logic (dynamic, no hardcoded paths)
- âœ… Orchestrator paths (no hardcoded references)
- âœ… Directory creation (WGP handles automatically)
- âœ… Test files (only documentation, not production)

---

## ğŸš€ Quick Start for Tomorrow

**Phase 1 is DONE. Here's what to do next:**

```bash
# 1. Run Phase 1.5 Validation (30 minutes)
# See: TOMORROW_VALIDATION_CHECKLIST.md

# Restart worker to activate Phase 1
python worker.py --main-output-dir ./outputs [your args...]

# Run test tasks (1-2 examples)
# - Submit a t2i or flux task (image)
# - Submit a vace or t2v task (video)

# Verify files in correct location
ls -lht outputs/*.{png,mp4} | head -10
find Wan2GP/outputs/ -name "*.mp4" -mmin -60 | wc -l  # Should be 0

# Check logs for confirmation
grep "OUTPUT_DIR" logs/*.log

# 2. If validation passes â†’ Ready for Phase 2!
```

**IMPORTANT:** Complete Phase 1.5 validation before implementing Phase 2. See section below for detailed checklist.

---

## Executive Summary

The Headless-Wan2GP project currently has a complex and inconsistent file output management system with files being saved to multiple locations (`/outputs/` and `/Wan2GP/outputs/`). This document outlines the current state, identifies problems, and proposes a comprehensive standardization plan to consolidate all outputs into a single directory structure with proper debug flag support.

**Current State:**
- 5.8GB in `/workspace/Headless-Wan2GP/outputs/` (2,485 MP4 files)
- 6.2GB in `/workspace/Headless-Wan2GP/Wan2GP/outputs/` (3,387 MP4 files)
- Inconsistent cleanup behavior across different task types
- Debug flag exists but may not be fully respected across all code paths

---

## 1. Current Architecture Analysis

### 1.1 Dual Output Directory System

The system currently maintains two separate output directories:

#### **Primary Output Directory: `/outputs/`**
- **Purpose:** Orchestrator tasks and worker-coordinated outputs
- **Configured via:** `--main-output-dir` flag (default: `./outputs`)
- **Reference:** `worker.py:96`
- **Structure:**
  ```
  outputs/
  â”œâ”€â”€ edit_video_run_YYYYMMDDHHMMSS/
  â”‚   â”œâ”€â”€ vlm_temp/
  â”‚   â”œâ”€â”€ keeper_clips/
  â”‚   â””â”€â”€ join_0/
  â”œâ”€â”€ join_clips_run_YYYYMMDDHHMMSS/
  â”‚   â”œâ”€â”€ join_0/
  â”‚   â”œâ”€â”€ vlm_temp/
  â”‚   â””â”€â”€ loop_temp/
  â””â”€â”€ inpaint_frames/TASK_ID/
  ```

#### **WGP Internal Directory: `/Wan2GP/outputs/`**
- **Purpose:** Direct generation outputs from WGP engine
- **Configured in:** `headless_wgp.py:309-312`
- **Code:**
  ```python
  absolute_outputs_path = os.path.abspath(
      os.path.join(os.path.dirname(self.wan_root), 'outputs')
  )
  wgp.server_config = {'save_path': absolute_outputs_path}
  ```
- **Structure:**
  ```
  Wan2GP/outputs/
  â”œâ”€â”€ 2025-12-17-13h03m43s_seed44846341_<prompt>.mp4  # Direct video outputs
  â”œâ”€â”€ qwen_inpaint_composites/
  â”œâ”€â”€ qwen_annotate_composites/
  â”œâ”€â”€ style_refs/
  â””â”€â”€ default_travel_output/
      â””â”€â”€ vlm_debug/
  ```

### 1.2 Task Types and Their Output Behaviors

#### **Orchestrator Tasks** (Save to `main_output_dir_base/`)
These coordinate child tasks and create run-specific directories:

| Task Type | Output Directory Pattern | Child Tasks | Cleanup Behavior |
|-----------|-------------------------|-------------|------------------|
| `travel_orchestrator` | `main_output_dir_base/` (no subdirectory) | `travel_segment`, `travel_stitch` | No cleanup (coordinates children) |
| `join_clips_orchestrator` | `main_output_dir_base/join_clips_run_RUNID/` | `join_clips_segment` | No cleanup (coordinates children) |
| `edit_video_orchestrator` | `main_output_dir_base/edit_video_run_RUNID/` | Multiple editing tasks | No cleanup (coordinates children) |

**Key Code References:**
- `source/orchestrators/travel.py`
- `source/orchestrators/join_clips.py`
- `source/orchestrators/edit_video.py`

#### **Direct Queue Tasks** (Save to `Wan2GP/outputs/`)
These tasks directly generate content via the WGP engine:

**Generation Tasks:**
- `wan_2_2_t2i` - Text to image
- `vace`, `vace_21`, `vace_22` - VACE video generation
- `flux` - Flux image generation
- `t2v`, `t2v_22` - Text to video
- `i2v`, `i2v_22` - Image to video
- `hunyuan` - HunyuanVideo generation
- `ltxv` - LTX Video generation
- `generate_video` - Generic video generation

**Editing Tasks:**
- `qwen_image_edit` - Qwen image editing
- `qwen_image_style` - Qwen style transfer
- `image_inpaint` - Image inpainting
- `annotated_image_edit` - Annotated editing

**Behavior:** Files saved with timestamp-based naming convention to `Wan2GP/outputs/` root directory.

#### **Segment Tasks** (Save to orchestrator directories)
These run as part of orchestrator workflows:

- `travel_segment` - Individual travel segment (orchestrator mode)
- `individual_travel_segment` - Standalone travel segment
- `join_clips_segment` - Individual clip joining
- `travel_stitch` - Stitches travel segments

**Behavior:** Save to parent orchestrator's directory structure.

#### **Specialized Tasks** (Mixed behavior)
- `magic_edit` - Uses temp directories
- `inpaint_frames` - Saves to `main_output_dir_base/inpaint_frames/TASK_ID/`
- `create_visualization` - Uses temp directories
- `extract_frame` - Extracts single frame
- `rife_interpolate_images` - RIFE frame interpolation

### 1.3 Current Cleanup System

#### Debug Flag Implementation
**Command-line argument:** `--debug` (worker.py:98)
**Global variable:** `debug_mode` (worker.py:47)

**Current Cleanup Logic** (`source/worker_utils.py:65-114`):

```python
def cleanup_generated_files(output_location: str, task_id: str, debug_mode: bool):
    if debug_mode:
        headless_logger.debug(f"Debug mode enabled - skipping file cleanup")
        return

    # Delete files/directories
    if file_path.exists() and file_path.is_file():
        file_path.unlink()
    elif file_path.exists() and file_path.is_dir():
        shutil.rmtree(file_path)

    _cleanup_temporary_files(task_id, debug_mode)
```

**When Cleanup Runs:**
- After task marked as `STATUS_COMPLETE` (worker.py:297)
- Only for non-orchestrator tasks
- Skipped if `debug_mode=True`

**Current Behavior:**
- **Production mode (no `--debug`):** Files deleted after upload/completion
- **Debug mode (`--debug`):** All files preserved locally
- **Orchestrator tasks:** Never cleaned up (they coordinate children)

---

## 2. Problems Identified

### 2.1 Inconsistent Output Locations

**Problem:** Files are saved to different locations based on task type, making it difficult to:
- Find outputs for specific tasks
- Manage disk space
- Implement consistent cleanup policies
- Track file usage and lifecycle

**Evidence:**
- Direct generation tasks â†’ `Wan2GP/outputs/`
- Orchestrator tasks â†’ `outputs/run_specific_dirs/`
- Segment tasks â†’ Parent orchestrator directories
- Some specialized tasks â†’ Various temp directories

### 2.2 Dual Directory System Complexity

**Problem:** Having two separate output directories creates:
- Confusion about where to find files
- Duplicate storage concerns
- Inconsistent path handling in code
- Difficulty in unified cleanup operations

**Root Cause:** The WGP engine has its own output path configuration that's independent of the worker's `--main-output-dir` setting.

**Code Location:** `headless_wgp.py:309` sets `Wan2GP/outputs/` hardcoded relative path

### 2.3 Incomplete Debug Flag Respect

**Problem:** The `--debug` flag exists but may not be consistently checked across all code paths:
- Some tasks may bypass the cleanup system
- WGP internal operations may not respect debug mode
- Temporary files may be cleaned up even in debug mode by individual functions

**Evidence:**
- Cleanup is only called from `worker.py:297` after task completion
- WGP internal file operations don't receive debug flag
- Comment in code: "Most temporary files are already cleaned up by their respective functions"

### 2.4 Run-to-Run Behavioral Differences

**Problem:** Different behavior between first and subsequent runs:
- First run may create directory structures
- Subsequent runs may reuse or conflict with existing directories
- Unclear file overwrite vs. append behavior
- Timestamp-based naming helps but doesn't fully solve the issue

**Impact:**
- Difficult to debug issues
- Unpredictable file accumulation
- Risk of file conflicts

### 2.5 Orchestrator Tasks Don't Clean Up

**Problem:** Orchestrator tasks never clean up their output directories:
- `join_clips_run_*` directories accumulate
- `edit_video_run_*` directories accumulate
- Travel orchestrator outputs accumulate

**Code Reference:** Worker cleanup (worker.py:297) only runs for completed non-orchestrator tasks

**Impact:** Even in production mode, orchestrator outputs persist indefinitely

---

## 3. Standardization Plan

### 3.1 Goals

1. **Single Output Directory:** All files saved to `--main-output-dir` (default: `/outputs/`)
2. **Consistent Structure:** Predictable subdirectory organization by task type
3. **Debug Flag Respect:** All file operations respect `--debug` flag
4. **Complete Cleanup:** In production mode (no `--debug`), all files are deleted after use
5. **Zero Breaking Changes:** Existing functionality must continue to work

### 3.1.1 Testing Strategy Overview

Each phase follows a **Test-Implement-Validate** loop:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  For Each Phase:                                    â”‚
â”‚                                                     â”‚
â”‚  1. Capture Baseline                               â”‚
â”‚     â””â”€> python tests/run_file_validation.py       â”‚
â”‚         --phase before                             â”‚
â”‚                                                     â”‚
â”‚  2. Write Tests First (if needed)                  â”‚
â”‚     â””â”€> Create specific validation for this phase â”‚
â”‚                                                     â”‚
â”‚  3. Implement Changes                              â”‚
â”‚     â””â”€> Make small, incremental code changes      â”‚
â”‚                                                     â”‚
â”‚  4. Validate Changes                               â”‚
â”‚     â””â”€> python tests/run_file_validation.py       â”‚
â”‚         --phase after                              â”‚
â”‚                                                     â”‚
â”‚  5. Run Integration Tests                          â”‚
â”‚     â””â”€> python tests/test_file_saving_integration â”‚
â”‚         --lightweight-only                         â”‚
â”‚                                                     â”‚
â”‚  6. Manual Smoke Tests                             â”‚
â”‚     â””â”€> Run 2-3 actual tasks manually             â”‚
â”‚                                                     â”‚
â”‚  7. Review & Fix or Commit                         â”‚
â”‚     â””â”€> If issues: fix and repeat from step 3     â”‚
â”‚     â””â”€> If clean: commit and move to next phase   â”‚
â”‚                                                     â”‚
â”‚  8. Monitor in Production (if deployed)            â”‚
â”‚     â””â”€> Watch metrics for 24-48 hours             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Success Criteria for Each Phase:**
- All validation tests pass
- No unexpected file location changes
- Debug mode works correctly
- Storage usage is reasonable
- No increase in error rates

### 3.2 Proposed Output Directory Structure

```
outputs/  (configurable via --main-output-dir)
â”œâ”€â”€ orchestrator_runs/
â”‚   â”œâ”€â”€ travel_RUNID/
â”‚   â”‚   â”œâ”€â”€ segments/
â”‚   â”‚   â””â”€â”€ final/
â”‚   â”œâ”€â”€ join_clips_RUNID/
â”‚   â”‚   â”œâ”€â”€ clips/
â”‚   â”‚   â”œâ”€â”€ vlm_temp/
â”‚   â”‚   â””â”€â”€ final/
â”‚   â””â”€â”€ edit_video_RUNID/
â”‚       â”œâ”€â”€ keeper_clips/
â”‚       â”œâ”€â”€ vlm_temp/
â”‚       â””â”€â”€ final/
â”œâ”€â”€ generation/
â”‚   â”œâ”€â”€ text_to_image/
â”‚   â”œâ”€â”€ text_to_video/
â”‚   â”œâ”€â”€ image_to_video/
â”‚   â””â”€â”€ vace/
â”œâ”€â”€ editing/
â”‚   â”œâ”€â”€ inpaint/
â”‚   â”œâ”€â”€ qwen_edit/
â”‚   â””â”€â”€ style_transfer/
â”œâ”€â”€ specialized/
â”‚   â”œâ”€â”€ frame_extraction/
â”‚   â”œâ”€â”€ interpolation/
â”‚   â””â”€â”€ visualization/
â””â”€â”€ temp/
    â””â”€â”€ [automatically cleaned temp files]
```

### 3.3 Implementation Steps

#### **Phase 1: Configuration Unification** (Low Risk)

**Goal:** Make WGP respect the worker's `--main-output-dir` setting

**Changes Required:**

1. **Modify `headless_wgp.py:309`:**
   ```python
   # OLD:
   absolute_outputs_path = os.path.abspath(
       os.path.join(os.path.dirname(self.wan_root), 'outputs')
   )

   # NEW:
   # Accept main_output_dir from worker configuration
   def __init__(self, wan_root: str, main_output_dir: str = None, ...):
       if main_output_dir is None:
           main_output_dir = os.path.join(
               os.path.dirname(wan_root), 'outputs'
           )
       absolute_outputs_path = os.path.abspath(main_output_dir)
   ```

2. **Pass `main_output_dir` from worker.py:**
   - Update WGP initialization calls to pass the configured output directory
   - Ensure all WGP instances receive this parameter

**Testing Loop for Phase 1:**

```bash
# Step 1: Capture Baseline
python tests/run_file_validation.py --phase before
# Save: before_phase1_snapshot.json

# Step 2: Write Phase-Specific Test (Optional)
# Create test that validates WGP respects main_output_dir

# Step 3: Implement Change #1 (headless_wgp.py)
# Modify __init__ to accept main_output_dir parameter

# Step 4: Quick Unit Test
python -c "
from headless_wgp import HeadlessTaskQueue
# Verify __init__ accepts new parameter without errors
# Verify old behavior still works (backwards compatibility)
"

# Step 5: Implement Change #2 (worker.py)
# Pass main_output_dir to WGP initialization

# Step 6: Integration Test - Lightweight
python tests/test_file_saving_integration.py --lightweight-only
# Expected: All tests pass, files in correct location

# Step 7: Validation - Full Comparison
python tests/run_file_validation.py --phase after
# Expected: Files now in outputs/ instead of Wan2GP/outputs/

# Step 8: Manual Smoke Tests
# Test 1: Run a simple generation task
python -c "
# Submit a test task, check output location
# Verify it appears in configured outputs/
"

# Test 2: Run with custom --main-output-dir
python worker.py --main-output-dir ./custom_outputs [...other args]
# Verify files appear in ./custom_outputs/

# Test 3: Test without parameter (backwards compatibility)
# Verify files still go to default location

# Step 9: Check Cleanup Behavior
python tests/test_file_saving_integration.py --lightweight-only --debug
# Verify files persist in debug mode

python tests/test_file_saving_integration.py --lightweight-only
# Verify files cleaned up in production mode

# Step 10: Review Results
cat test_comparison_report.txt
# Check for unexpected changes

# Step 11: If All Green - Commit
git add headless_wgp.py worker.py
git commit -m "Phase 1: Unify output directory configuration"
git push

# Step 12: Monitor (if deployed)
# Watch logs for 24-48 hours
# Check disk usage trends
# Monitor error rates
```

**Expected Changes:**
- Files from direct generation tasks move from `Wan2GP/outputs/` to `outputs/`
- All files now respect `--main-output-dir` configuration
- Backwards compatibility maintained (default behavior unchanged)

**Validation Checklist:**
- [ ] All task types output to configured directory
- [ ] Default behavior works (no main_output_dir specified)
- [ ] Custom output directory works (--main-output-dir /custom/path)
- [ ] No files still going to old Wan2GP/outputs/ location
- [ ] Integration tests pass
- [ ] Manual smoke tests pass
- [ ] Debug mode still works
- [ ] No increase in errors

**Rollback Plan:**
- Keep old path as fallback if parameter not provided
- Add feature flag: `USE_UNIFIED_OUTPUT_DIR` (default: True)
- If issues: set flag to False and revert

---

#### **Phase 1.5: Production Validation** (REQUIRED - Zero Risk)

**Goal:** Validate Phase 1 works correctly in production before proceeding to Phase 2

**Why This Phase:**
- Phase 1 changes WHERE 6.2GB of files are saved
- Need to verify consolidation works as expected
- Catch any issues before adding more changes
- Build confidence for Phase 2

**Duration:** 30 minutes to 24 hours (depending on thoroughness)

**Testing Steps:**

```bash
# Step 1: Restart Worker (Activates Phase 1)
# Stop current worker, then restart
python worker.py --main-output-dir ./outputs [your other args...]

# Step 2: Check Logs for Output Directory Messages
tail -f logs/*.log | grep "OUTPUT_DIR"
# Expected: Should see logs showing configured output directory

# Step 3: Run Test Tasks (Manually or via API)

# Test 3a: Image Generation Task (t2i/flux)
# Submit a simple text-to-image task
# Expected: Image should appear in outputs/ NOT Wan2GP/outputs/

# Test 3b: Video Generation Task (vace/t2v)
# Submit a simple video generation task
# Expected: Video should appear in outputs/ NOT Wan2GP/outputs/

# Test 3c: Orchestrator Task (join_clips)
# Submit a join clips task
# Expected: Should work as before

# Step 4: Verify File Locations
ls -lh outputs/ | head -20
# Expected: See new image/video files

ls -lh Wan2GP/outputs/ | head -20
# Expected: No NEW files created (old files may remain)

# Step 5: Check File Counts
find outputs/ -name "*.mp4" -mmin -60 | wc -l
# Should show recently created videos

find Wan2GP/outputs/ -name "*.mp4" -mmin -60 | wc -l
# Should be 0 (no recent files)

# Step 6: Monitor for Errors
grep -i "error\|fail\|exception" logs/*.log | tail -20
# Check for any path-related errors

# Step 7: Verify Storage URLs Work
# If using Supabase, check that uploaded file URLs still resolve
# Test a few URLs from recent tasks
```

**Validation Checklist:**

- [ ] Worker starts successfully with no errors
- [ ] `[OUTPUT_DIR]` debug logs show correct path
- [ ] Image generation tasks save to configured directory
- [ ] Video generation tasks save to configured directory
- [ ] Orchestrator tasks complete successfully
- [ ] No new files appear in `Wan2GP/outputs/`
- [ ] File uploads to Supabase work (if applicable)
- [ ] No path-related errors in logs
- [ ] Storage usage matches expectations

**Quick Validation (30 minutes):**
- Run steps 1-4
- Submit 1-2 test tasks
- Verify files in correct location
- If all âœ… â†’ Proceed to Phase 2

**Thorough Validation (24 hours):**
- Run all steps
- Monitor production traffic
- Check disk usage trends
- Wait for variety of task types
- Review logs for anomalies
- If all âœ… â†’ Proceed to Phase 2

**If Issues Found:**

1. **Files still going to Wan2GP/outputs/**
   - Check worker was restarted after code deploy
   - Verify `main_output_dir` is being passed
   - Check logs for `[OUTPUT_DIR]` messages

2. **Path errors in logs**
   - Check directory permissions
   - Verify path is absolute not relative
   - Check disk space

3. **Upload failures**
   - Verify edge function can access new paths
   - Check Supabase configuration
   - Test manual upload

**Success Criteria:**

âœ… All new files appear in `outputs/` directory
âœ… No new files in `Wan2GP/outputs/`
âœ… All task types work correctly
âœ… No errors in logs
âœ… File uploads work (if applicable)

**When Complete:**

âœ… Phase 1 is VALIDATED in production
âœ… Safe to proceed to Phase 2
âœ… Can commit to Phase 2 changes with confidence

---

#### **Phase 2: Standardize Task Output Paths** (Medium Risk)

**Goal:** Create consistent subdirectory structure for all task types

**Changes Required:**

1. **Update `source/common_utils.py` - `prepare_output_path()` function:**
   ```python
   def prepare_output_path(
       task_id: str,
       filename: str,
       main_output_dir_base: Path,
       task_type: str = None,  # NEW PARAMETER
       *,
       dprint=lambda *_: None,
       custom_output_dir: str | Path | None = None
   ) -> tuple[Path, str]:
       if custom_output_dir:
           output_dir_for_task = Path(custom_output_dir)
       else:
           # NEW: Create task-type-specific subdirectory
           if task_type:
               type_dir = _get_task_type_directory(task_type)
               output_dir_for_task = main_output_dir_base / type_dir
           else:
               output_dir_for_task = main_output_dir_base

       output_dir_for_task.mkdir(parents=True, exist_ok=True)
       # ... rest of function
   ```

2. **Add task type mapping function:**
   ```python
   def _get_task_type_directory(task_type: str) -> str:
       """Map task types to their standard output subdirectories."""
       TASK_TYPE_DIRS = {
           # Orchestrators
           'travel_orchestrator': 'orchestrator_runs/travel',
           'join_clips_orchestrator': 'orchestrator_runs/join_clips',
           'edit_video_orchestrator': 'orchestrator_runs/edit_video',

           # Generation
           'wan_2_2_t2i': 'generation/text_to_image',
           't2v': 'generation/text_to_video',
           't2v_22': 'generation/text_to_video',
           'i2v': 'generation/image_to_video',
           'i2v_22': 'generation/image_to_video',
           'vace': 'generation/vace',
           'vace_21': 'generation/vace',
           'vace_22': 'generation/vace',

           # Editing
           'image_inpaint': 'editing/inpaint',
           'qwen_image_edit': 'editing/qwen_edit',
           'qwen_image_style': 'editing/style_transfer',

           # Specialized
           'extract_frame': 'specialized/frame_extraction',
           'rife_interpolate_images': 'specialized/interpolation',
           'create_visualization': 'specialized/visualization',

           # Default
           'default': 'misc'
       }
       return TASK_TYPE_DIRS.get(task_type, TASK_TYPE_DIRS['default'])
   ```

3. **Update all task handlers to pass `task_type`:**
   - Modify each task handler in `worker.py` to pass its task type
   - Update orchestrator task handlers to use new structure

**Testing Loop for Phase 2:**

```bash
# Step 1: Capture Baseline (Post-Phase 1)
python tests/run_file_validation.py --phase before
# This captures state after Phase 1

# Step 2: Create Task Type Validation Test
cat > tests/test_task_type_directories.py << 'EOF'
"""Validate task-type-specific directories."""
import os
from pathlib import Path

def test_task_type_directories():
    """Test that each task type goes to correct directory."""
    test_cases = {
        'wan_2_2_t2i': 'outputs/generation/text_to_image',
        'vace': 'outputs/generation/vace',
        'join_clips_orchestrator': 'outputs/orchestrator_runs/join_clips',
        'extract_frame': 'outputs/specialized/frame_extraction',
    }

    for task_type, expected_dir in test_cases.items():
        # Simulate task, verify output location
        pass  # Implementation

if __name__ == '__main__':
    test_task_type_directories()
    print("âœ“ All task types use correct directories")
EOF

# Step 3: Implement Change #1 (prepare_output_path)
# Add task_type parameter and directory mapping

# Step 4: Unit Test the Mapping Function
python -c "
from source.common_utils import _get_task_type_directory

# Test each task type
assert _get_task_type_directory('vace') == 'generation/vace'
assert _get_task_type_directory('join_clips_orchestrator') == 'orchestrator_runs/join_clips'
print('âœ“ Task type mapping works')
"

# Step 5: Update Task Handlers Incrementally
# Start with ONE task type (e.g., extract_frame)
# Test it thoroughly before moving to next

# Test single task type
python tests/test_file_saving_integration.py --tasks extract_frame
# Verify: files appear in outputs/specialized/frame_extraction/

# Step 6: Once one works, update remaining task types
# Update in batches: orchestrators, generation, editing, specialized

# Step 7: Integration Test - All Task Types
python tests/test_file_saving_integration.py --lightweight-only
# Expected: All task types in correct subdirectories

# Step 8: Validation - Full Comparison
python tests/run_file_validation.py --phase after

# Step 9: Manual Smoke Tests
# Test each task category:

# Test Generation Task
# python submit_task.py --task-type vace --prompt "test"
# Verify: outputs/generation/vace/

# Test Orchestrator
# python submit_task.py --task-type join_clips_orchestrator --clips [...]
# Verify: outputs/orchestrator_runs/join_clips/

# Test Specialized
# python submit_task.py --task-type extract_frame [...]
# Verify: outputs/specialized/frame_extraction/

# Step 10: Check Backwards Compatibility
# Run without task_type parameter
# Verify: falls back to main output dir (not crash)

# Step 11: Directory Structure Validation
python -c "
from pathlib import Path
import os

# Check directory structure is clean
outputs = Path('outputs')
expected_dirs = [
    'generation/text_to_image',
    'generation/vace',
    'orchestrator_runs/join_clips',
    'editing/inpaint',
    'specialized/frame_extraction'
]

for d in expected_dirs:
    assert (outputs / d).exists() or True  # Will be created on first use
    print(f'âœ“ {d}')
"

# Step 12: Review Results
cat test_comparison_report.txt
# Expected: Files moved from flat structure to organized subdirectories

# Step 13: If All Green - Commit
git add source/common_utils.py worker.py source/task_registry.py
git commit -m "Phase 2: Standardize task output directory structure"
git push

# Step 14: Monitor
# Watch for any file-not-found errors
# Check that file URLs still resolve
```

**Expected Changes:**
- Files organized into task-type-specific subdirectories
- Easier to find outputs for specific task types
- Cleaner, more maintainable structure

**Validation Checklist:**
- [ ] Each task type outputs to correct subdirectory
- [ ] Directory structure matches proposed design
- [ ] No files in wrong locations
- [ ] File URLs/paths still resolve correctly
- [ ] Backwards compatibility (task_type=None works)
- [ ] Integration tests pass for all task types
- [ ] Manual smoke tests pass
- [ ] No increase in errors

**Rollback Plan:**
- Keep `task_type` parameter optional (defaults to old behavior)
- Add configuration flag: `USE_TASK_TYPE_DIRS` (default: True)
- If issues: set flag to False, files go to root output dir
- Keep old directory structure for 30 days (migration period)

---

#### **Phase 3: Enhanced Debug Flag Support** (Medium Risk)

**Goal:** Ensure all file operations respect the debug flag

**Changes Required:**

1. **Create centralized file operation context:**
   ```python
   # NEW FILE: source/file_context.py

   from contextvars import ContextVar

   # Global context for debug mode
   _debug_mode: ContextVar[bool] = ContextVar('debug_mode', default=False)

   def set_debug_mode(enabled: bool):
       """Set global debug mode for current context."""
       _debug_mode.set(enabled)

   def is_debug_mode() -> bool:
       """Check if debug mode is enabled."""
       return _debug_mode.get()

   def should_cleanup_file() -> bool:
       """Returns True if files should be cleaned up (not in debug mode)."""
       return not is_debug_mode()
   ```

2. **Initialize context in worker.py:**
   ```python
   # In parse_args() or main():
   from source.file_context import set_debug_mode

   args = parse_args()
   set_debug_mode(args.debug)
   ```

3. **Update all cleanup calls:**
   ```python
   # Replace direct debug_mode parameter with context check:
   from source.file_context import should_cleanup_file

   def cleanup_generated_files(output_location: str, task_id: str):
       if not should_cleanup_file():
           headless_logger.debug("Debug mode - skipping cleanup")
           return
       # ... cleanup logic
   ```

4. **Add cleanup to WGP operations:**
   - Inject debug context into WGP internal operations
   - Add cleanup hooks after WGP generation completes

**Testing Loop for Phase 3:**

```bash
# Step 1: Capture Baseline (Post-Phase 2)
python tests/run_file_validation.py --phase before

# Step 2: Create Debug Mode Validation Test
cat > tests/test_debug_mode_cleanup.py << 'EOF'
"""Validate debug mode prevents all cleanup."""
import os
from pathlib import Path
import sys
sys.path.insert(0, str(Path.cwd()))

def test_debug_mode_preserves_files():
    """Run tasks with debug mode, verify files persist."""
    # Run task with debug mode
    # Check files exist after completion
    # Expected: Files persist
    pass

def test_production_mode_cleans_files():
    """Run tasks without debug mode, verify cleanup."""
    # Run task without debug mode
    # Check files deleted after completion
    # Expected: Files cleaned up
    pass

if __name__ == '__main__':
    test_debug_mode_preserves_files()
    test_production_mode_cleans_files()
    print("âœ“ Debug mode behavior validated")
EOF

# Step 3: Implement Change #1 (Create file_context.py)
# Create centralized context management

# Step 4: Unit Test Context Management
python -c "
from source.file_context import set_debug_mode, is_debug_mode, should_cleanup_file

# Test default
assert not is_debug_mode()
assert should_cleanup_file()

# Test debug mode
set_debug_mode(True)
assert is_debug_mode()
assert not should_cleanup_file()

# Test production mode
set_debug_mode(False)
assert not is_debug_mode()
assert should_cleanup_file()

print('âœ“ Context management works')
"

# Step 5: Update cleanup_generated_files (incremental)
# First, update worker_utils.py to use context

# Step 6: Test cleanup with context (debug mode)
python tests/test_file_saving_integration.py --lightweight-only --debug
# Expected: All files persist, no cleanup

# Step 7: Test cleanup with context (production mode)
python tests/test_file_saving_integration.py --lightweight-only
# Expected: Files cleaned up after tasks complete

# Step 8: Update all cleanup call sites
# Find all places that clean up files
grep -r "cleanup_generated_files\|unlink\|remove\|rmtree" source/

# Update each one to check should_cleanup_file()

# Step 9: Test Each Task Type Individually
# For each task type, test both modes:

# Test 1: extract_frame
python -c "
# Submit extract_frame task with --debug
# Verify output file persists
"
python -c "
# Submit extract_frame task without --debug
# Verify output file cleaned up
"

# Test 2: join_clips_orchestrator
# ... similar for each task type

# Step 10: Integration Test - Debug Mode
python tests/test_file_saving_integration.py --lightweight-only --debug \
    --save-results debug_mode_results.json

# Verify: No files removed
python -c "
import json
with open('debug_mode_results.json') as f:
    results = json.load(f)
    for test in results['tests'].values():
        assert test.get('files_removed', 0) == 0, f'Files removed in debug mode!'
print('âœ“ Debug mode: no files removed')
"

# Step 11: Integration Test - Production Mode
python tests/test_file_saving_integration.py --lightweight-only \
    --save-results production_mode_results.json

# Check cleanup happened (for non-orchestrator tasks)
python -c "
import json
with open('production_mode_results.json') as f:
    results = json.load(f)
    # Orchestrators don't clean up, but direct tasks should
    # This validates cleanup logic is working
print('âœ“ Production mode: cleanup working')
"

# Step 12: Validation - Full Comparison
python tests/run_file_validation.py --phase after

# Step 13: Manual Smoke Tests
# Test 1: Debug mode preserves files
# worker.py --debug [...args]
# ls outputs/  # Should show files

# Test 2: Production mode cleans files
# worker.py [...args]
# ls outputs/  # Should be empty or only have orchestrator outputs

# Test 3: Toggle debug mode mid-session
# Start worker with --debug
# Submit task, verify files persist
# Restart worker without --debug
# Submit task, verify files cleaned

# Step 14: Grep for Bypassed Cleanup
# Look for cleanup code that doesn't check debug mode
grep -r "\.unlink\|os\.remove\|shutil\.rmtree" source/ \
    | grep -v "should_cleanup_file\|is_debug_mode"
# Investigate any matches

# Step 15: Test WGP Internal Cleanup
# WGP might have its own cleanup - verify it respects debug mode
python -c "
# Test WGP respects debug context
# This might require monkey-patching or WGP changes
"

# Step 16: Review Results
cat test_comparison_report.txt
# Expected: No functional changes, only cleanup behavior

# Step 17: Compare Debug vs Production Runs
diff debug_mode_results.json production_mode_results.json
# Expected: Different cleanup behavior, same task success rates

# Step 18: If All Green - Commit
git add source/file_context.py source/worker_utils.py worker.py
git commit -m "Phase 3: Centralize and enforce debug mode respect"
git push

# Step 19: Monitor
# Watch for files accumulating (debug mode working)
# Watch for unexpected cleanup (production mode working)
# Monitor disk usage trends
```

**Expected Changes:**
- Debug mode consistently prevents ALL cleanup
- Production mode enables cleanup across all code paths
- No files cleaned up unexpectedly in debug mode
- Proper cleanup in production mode

**Validation Checklist:**
- [ ] Debug mode prevents all cleanup (test all task types)
- [ ] Production mode enables cleanup (test all task types)
- [ ] Context propagates correctly through call stack
- [ ] WGP internal operations respect debug mode
- [ ] No cleanup bypass paths remain
- [ ] Integration tests pass in both modes
- [ ] Manual smoke tests pass
- [ ] Disk usage reasonable in both modes

**Rollback Plan:**
- Context var defaults to False (cleanup enabled - safe default)
- Keep old parameter-based approach as fallback
- Add configuration flag: `USE_CONTEXT_DEBUG_MODE` (default: True)
- If issues: revert to passing debug_mode parameter explicitly

---

#### **Phase 4: Orchestrator Cleanup** (High Risk)

**Goal:** Enable cleanup for orchestrator tasks while preserving necessary files

**Problem:** Orchestrators coordinate multiple child tasks and can't be cleaned up until all children complete.

**Solution:**

1. **Track orchestrator lifecycle:**
   ```python
   # Add to database schema or in-memory tracking
   orchestrator_runs = {
       'run_id': {
           'status': 'running',  # running, completed, failed
           'child_tasks': ['task_id_1', 'task_id_2'],
           'output_dir': '/path/to/run',
           'created_at': timestamp
       }
   }
   ```

2. **Cleanup on orchestrator completion:**
   ```python
   def complete_orchestrator_run(run_id: str, debug_mode: bool):
       """Called when orchestrator and all children complete."""
       run_info = get_orchestrator_run(run_id)

       # Verify all children completed
       if not all_children_completed(run_info['child_tasks']):
           return

       # Cleanup if not in debug mode
       if not debug_mode:
           cleanup_generated_files(run_info['output_dir'], run_id, debug_mode)
   ```

3. **Add orchestrator completion detection:**
   - Monitor child task completion
   - Trigger orchestrator cleanup when all children done

**Testing:**
- Run orchestrator tasks and verify cleanup after all children complete
- Test with debug flag to ensure files persist
- Test partial failure scenarios (some children fail)

**Rollback Plan:**
- Add configuration flag: `--cleanup-orchestrators` (default: False)
- Gradually enable after validation period

---

#### **Phase 5: Migration and Cleanup** (Low Risk)

**Goal:** Clean up old files and provide migration path

**Changes Required:**

1. **Add migration script:**
   ```python
   # scripts/migrate_output_structure.py

   def migrate_outputs(old_outputs_dir: str, new_outputs_dir: str, dry_run: bool = True):
       """
       Migrate files from old structure to new standardized structure.

       Args:
           old_outputs_dir: Path to old outputs (e.g., 'Wan2GP/outputs')
           new_outputs_dir: Path to new outputs (e.g., 'outputs')
           dry_run: If True, only report what would be done
       """
       # Scan old directory
       # Infer task types from filenames/structure
       # Move to appropriate new locations
       # Report statistics
   ```

2. **Add cleanup script:**
   ```python
   # scripts/cleanup_old_outputs.py

   def cleanup_old_outputs(outputs_dir: str, days_old: int = 7, dry_run: bool = True):
       """
       Clean up old output files that are no longer needed.

       Args:
           outputs_dir: Directory to clean
           days_old: Only delete files older than this many days
           dry_run: If True, only report what would be deleted
       """
       # Find old files
       # Report size savings
       # Delete if not dry_run
   ```

**Testing:**
- Run migration script with `--dry-run` first
- Verify no data loss
- Check disk space savings

---

### 3.4 Implementation Priority & Risk Assessment

| Phase | Priority | Risk Level | Estimated Impact | Dependencies |
|-------|----------|------------|------------------|--------------|
| Phase 1: Configuration Unification | HIGH | Low | 6.2GB consolidation | None |
| Phase 2: Standardize Paths | MEDIUM | Medium | Better organization | Phase 1 |
| Phase 3: Enhanced Debug Support | HIGH | Medium | Proper debug behavior | Phase 1 |
| Phase 4: Orchestrator Cleanup | LOW | High | Disk space savings | Phases 1-3 |
| Phase 5: Migration | LOW | Low | Historical cleanup | Phases 1-2 |

### 3.5 Testing Strategy

**Unit Tests:**
- Test each task type output path generation
- Test cleanup logic with debug on/off
- Test orchestrator lifecycle tracking

**Integration Tests:**
- Run complete workflows (orchestrator + children)
- Verify file locations at each step
- Test cleanup timing and completeness

**Validation Tests:**
- Compare output quality before/after changes
- Verify no file corruption
- Check all URLs still resolve correctly

**Regression Tests:**
- Run existing test suite
- Monitor production metrics
- Check error rates

---

## 4. Breaking Changes and Mitigation

### 4.1 Potential Breaking Changes

1. **Output Path Changes:**
   - **Risk:** Code that hardcodes paths to `Wan2GP/outputs/` will break
   - **Mitigation:** Keep old path as symlink during transition period
   - **Detection:** Search codebase for hardcoded path references

2. **File Naming Changes:**
   - **Risk:** Code expecting specific filename patterns may break
   - **Mitigation:** Maintain filename compatibility, only change directories
   - **Detection:** Grep for filename pattern matching code

3. **Cleanup Timing Changes:**
   - **Risk:** Code expecting files to persist may break
   - **Mitigation:** Ensure cleanup only happens after all processing complete
   - **Detection:** Monitor task failure rates

### 4.2 Migration Path

**Option A: Big Bang (Faster but riskier)**
- Implement all phases at once
- Thorough pre-deployment testing
- Quick rollback plan if issues arise

**Option B: Gradual (Slower but safer) - RECOMMENDED**
- Deploy Phase 1 first, monitor for 1 week
- Deploy Phase 2, monitor for 1 week
- Deploy Phase 3, monitor for 1 week
- Deploy Phase 4 only after full validation
- Phase 5 can be run offline

**Rollback Strategy:**
- Keep feature flags for each phase
- Ability to revert to old behavior via configuration
- Database backups before each phase
- Code version tags for quick rollback

---

## 5. Monitoring and Validation

### 5.1 Metrics to Track

**Disk Usage:**
- Total outputs directory size over time
- File count by task type
- Cleanup effectiveness (files deleted vs. created)

**Performance:**
- Task completion time (before/after changes)
- File I/O latency
- Cleanup operation duration

**Reliability:**
- Task success/failure rates
- File not found errors
- Path resolution errors

**Debug Mode:**
- Files persisted when --debug used
- Files cleaned when --debug not used
- Debug mode adoption rate

### 5.2 Success Criteria

**Phase 1 Success:**
- [ ] All new files appear in configured `--main-output-dir`
- [ ] No files created in `Wan2GP/outputs/` (except legacy operations)
- [ ] All task types continue to work correctly
- [ ] No increase in error rates

**Phase 2 Success:**
- [ ] Files organized into correct subdirectories
- [ ] No path resolution errors
- [ ] Easy to find files by task type
- [ ] Documentation reflects new structure

**Phase 3 Success:**
- [ ] `--debug` flag prevents all cleanup
- [ ] No `--debug` flag enables all cleanup
- [ ] 100% of file operations respect debug mode
- [ ] Logs clearly indicate cleanup actions

**Phase 4 Success:**
- [ ] Orchestrator directories cleaned after completion
- [ ] Disk space usage stabilizes or decreases
- [ ] No premature cleanup (files deleted while in use)
- [ ] All child tasks complete before orchestrator cleanup

**Phase 5 Success:**
- [ ] Old directory structure migrated
- [ ] Historical files cleaned up (if safe)
- [ ] Disk space savings achieved (target: 50%+ reduction)
- [ ] No data loss during migration

---

## 6. Documentation Updates Needed

### 6.1 User-Facing Documentation

1. **Update README.md:**
   - Document new output directory structure
   - Explain `--debug` flag behavior clearly
   - Provide examples of finding outputs

2. **Create OUTPUT_STRUCTURE.md:**
   - Detailed map of output directories
   - Task type to directory mapping
   - Examples for each task type

3. **Update CLI help text:**
   - Clarify `--main-output-dir` behavior
   - Document `--debug` flag effects
   - Add examples

### 6.2 Developer Documentation

1. **Create CONTRIBUTING.md section:**
   - How to add new task types
   - How to ensure proper output path usage
   - Testing checklist for file operations

2. **Update architecture docs:**
   - Explain output path resolution
   - Document cleanup lifecycle
   - Show debug mode integration

3. **Add code comments:**
   - Annotate key file operation points
   - Explain cleanup timing logic
   - Document orchestrator lifecycle

---

## 7. Open Questions

1. **Supabase Upload Behavior:**
   - Do we still need local files after upload to Supabase?
   - Should cleanup happen immediately after upload or after task completion?
   - What happens if upload fails?

2. **Multi-Worker Scenarios:**
   - How do multiple workers share the same output directory?
   - Are there file locking concerns?
   - Should each worker have its own subdirectory?

3. **Large File Handling:**
   - Should we stream large files instead of writing to disk?
   - Is there a size threshold for immediate cleanup?
   - Memory vs. disk tradeoffs?

4. **Backwards Compatibility:**
   - How long do we maintain old path support?
   - Do we need a deprecation timeline?
   - What about external tools that reference old paths?

5. **Error Recovery:**
   - What happens to files when tasks fail?
   - Should failed task outputs be preserved for debugging?
   - How long do we keep failed task artifacts?

---

## 8. Next Steps

### Immediate Actions (Week 1)

1. **[ ] Review this document with team**
   - Gather feedback on proposed approach
   - Answer open questions
   - Adjust plan based on input

2. **[ ] Create detailed task breakdown**
   - File tickets for each phase
   - Estimate effort for each task
   - Assign ownership

3. **[ ] Set up monitoring**
   - Add disk usage tracking
   - Create output directory dashboards
   - Set up alerts for anomalies

### Short Term (Weeks 2-4)

4. **[ ] Implement Phase 1**
   - Unify configuration
   - Test thoroughly
   - Deploy to production

5. **[ ] Begin Phase 2 implementation**
   - Create task type mapping
   - Update path resolution
   - Test with representative tasks

### Medium Term (Months 2-3)

6. **[ ] Complete Phases 2-3**
   - Standardize all paths
   - Full debug mode support
   - Update documentation

7. **[ ] Evaluate Phase 4 necessity**
   - Measure disk usage with Phases 1-3
   - Decide if orchestrator cleanup is still needed
   - Plan implementation if yes

### Long Term (Month 4+)

8. **[ ] Run Phase 5 migration**
   - Clean up historical files
   - Consolidate old structure
   - Archive if needed

9. **[ ] Continuous improvement**
   - Monitor metrics
   - Optimize based on real usage
   - Refactor as needed

---

## 9. Conclusion

The current file output system has grown organically and now requires standardization. This plan provides a structured approach to:

- **Consolidate** outputs into a single configurable directory
- **Standardize** directory structure across all task types
- **Respect** the debug flag consistently
- **Enable** proper cleanup in production mode
- **Maintain** backwards compatibility during transition

By implementing these changes in phases, we can minimize risk while achieving the benefits of a cleaner, more maintainable file management system.

**Estimated Overall Impact:**
- **Disk space savings:** 30-50% reduction (currently 12GB total)
- **Developer experience:** Clearer output locations, easier debugging
- **System reliability:** Consistent cleanup prevents disk full scenarios
- **Maintenance:** Easier to understand and modify file handling code

**Recommended Approach:** Gradual implementation (Option B) with Phase 1 starting immediately.

---

## 10. Why This Plan Will Work the First Time

### 10.1 Test-First Methodology

This plan is designed for success through comprehensive testing at every step:

**1. Baseline Capture**
- Snapshot current behavior before ANY changes
- Provides clear comparison point
- Detects unexpected changes immediately

**2. Incremental Changes**
- Each phase is small and focused
- Test after each change, not at the end
- Fix issues immediately while context is fresh

**3. Automated Validation**
- File snapshot tool detects all file operation changes
- Integration tests verify actual task execution
- No manual guessing about what changed

**4. Multiple Validation Layers**
```
Unit Tests â†’ Integration Tests â†’ Snapshot Comparison â†’ Manual Smoke Tests â†’ Production Monitor
```

**5. Built-in Rollback**
- Feature flags for each phase
- Backwards compatibility maintained
- Can revert without data loss

### 10.2 Risk Mitigation Approach

**Lowest Risk First:**
- Phase 1 (Low Risk) â†’ Phase 2 (Medium Risk) â†’ Phase 3 (Medium Risk) â†’ Phase 4 (High Risk)
- Each phase reduces risk for the next
- Can stop at any phase if needed

**Validation Checkpoints:**
- âœ“ After each code change
- âœ“ After each task type update
- âœ“ After each phase completion
- âœ“ After deployment (monitoring)

**Clear Success Criteria:**
- Explicit checklist for each phase
- Objective pass/fail measurements
- No ambiguity about "done"

### 10.3 What Makes This Different from Typical Refactoring

**Typical Refactoring:**
1. Make changes
2. Hope nothing breaks
3. Fix issues in production
4. Repeat until stable

**This Plan:**
1. Capture baseline
2. Make small change
3. Validate immediately
4. Fix before moving forward
5. Commit when validated
6. Monitor in production
7. Repeat for next phase

**Key Difference:** We know immediately if something broke, not after deployment.

### 10.4 Testing Framework Advantages

The custom testing framework provides:

1. **File-level granularity**: See exactly which files moved where
2. **Size tracking**: Detect unexpected bloat or cleanup issues
3. **Directory structure validation**: Ensure organization matches plan
4. **Debug mode validation**: Verify cleanup behavior in both modes
5. **Before/after comparison**: Clear diff of what changed

**Example Output:**
```
================================================================================
FILE COMPARISON SUMMARY
================================================================================

Added files: 18
  + outputs/generation/vace/test_output.mp4
  + outputs/orchestrator_runs/join_clips/run_123/

Removed files: 0

Modified files: 0

Total size difference: +52,041,367 bytes

âœ“ All changes expected
âœ“ No unexpected file locations
âœ“ Cleanup behavior correct
================================================================================
```

### 10.5 Success Probability Estimate

Based on the testing approach and incremental methodology:

**Phase 1 (Configuration Unification):**
- Success Probability: **95%**
- Why: Simple parameter passing, comprehensive tests, easy rollback
- Risk: Very low - backwards compatible by default

**Phase 2 (Standardize Paths):**
- Success Probability: **90%**
- Why: Incremental task type updates, tested individually
- Risk: Low - optional parameter, falls back gracefully

**Phase 3 (Enhanced Debug Support):**
- Success Probability: **85%**
- Why: Centralized context, but needs thorough cleanup audit
- Risk: Medium - need to find all cleanup locations

**Phase 4 (Orchestrator Cleanup):**
- Success Probability: **75%**
- Why: Complex timing, needs careful orchestration
- Risk: High - can skip this phase if not critical

**Overall Plan Success Probability: ~90%**

The high success rate comes from:
- Test-first approach
- Incremental changes
- Multiple validation layers
- Clear rollback strategy
- Option to skip high-risk phases

### 10.6 Timeline to Working First Time

**Realistic Timeline:**
- Phase 1: 1-2 days (implementation + validation)
- Phase 2: 2-3 days (incremental task type updates)
- Phase 3: 2-3 days (audit + implementation)
- Phase 4: 3-5 days (if needed)

**Total: 8-13 days for Phases 1-3 (recommended scope)**

Each phase is validated before moving to the next, so "working the first time" means:
- Each phase works when you move to the next phase
- No need to go back and fix previous phases
- Cumulative validation ensures integration

### 10.7 Final Checklist Before Starting

Before implementing Phase 1, ensure:

- [ ] Test framework files exist and run successfully
- [ ] Baseline snapshot captured
- [ ] You understand the Test-Implement-Validate loop
- [ ] You have rollback plan ready
- [ ] You're starting with Phase 1 (not jumping ahead)
- [ ] You'll validate after EACH change (not batch validation)
- [ ] You have ~2 hours for Phase 1 implementation + testing
- [ ] You can run lightweight integration tests

**If all checkboxes marked:** You're ready to start with high confidence of success.

**If any unchecked:** Address those items first. The preparation is worth it.

---

**Document prepared based on codebase analysis on 2025-12-17**

**Testing framework validated and ready to use.**

**For questions or feedback, please discuss with the team before implementation.**

**Remember: The test framework is your safety net. Use it at every step.**
