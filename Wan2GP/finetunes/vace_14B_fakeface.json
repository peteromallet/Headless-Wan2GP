{
    "model": {
        "name": "FakeFace Experimental Cocktail 14B",
        "architecture": "t2v",
        "modules": [
        ],
        "description": "This model uses custom FakeFace fp8 quantized weights with the cocktail LoRA combination. Configured as T2V architecture without VACE modules for fp8 compatibility. The Detail Enhancer LoRA weight has been reduced to improve identity preservation.",
        "URLs": [
            "https://huggingface.co/CCP6/FakeVace2.2/resolve/main/Fake-Vace2.2-High_fp8_e4m3fn.safetensors"
        ],
        "URLs2": [
            "https://huggingface.co/CCP6/FakeVace2.2/resolve/main/Fake-Vace2.2-Low_fp8_e4m3fn.safetensors"
        ],
        "loras": [],
        "loras_multipliers": [],
		"group": "wan2_2",
		"auto_quantize": false,
		"fp8_quantized": true
    },
    "num_inference_steps": 6,
    "guidance_scale": 3,
    "guidance2_scale": 1,
    "flow_shift": 3.0,
    "sample_solver": "dpm++",
    "control_net_weight": 1.3,
    "control_net_weight2": 1.0,
    "sampler_cfg_presets": {
        "euler": {"guidance_scale": 1.0, "flow_shift": 2.0},
        "unipc": {"guidance_scale": 1.2, "flow_shift": 2.5},
        "dpm++": {"guidance_scale": 3.0, "guidance2_scale": 1.0, "flow_shift": 3.0, "num_inference_steps": 6},
        "causvid": {"guidance_scale": 1.0, "flow_shift": 1.0}
    },
	"switch_threshold" : 875	
}
